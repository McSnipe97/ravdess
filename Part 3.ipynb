{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 of RAVDESS Emotional Speech Recognition project by Anuj Soni (mcsnipe97)\n",
    "\n",
    "## Modelling, training, testing\n",
    "---\n",
    "We will build a baseline CNN1D model.\n",
    "\n",
    "Firstlt, I want to thank the author for their excellent dataset, without it, writing this notebook could not have been possible. \n",
    "\n",
    "The link for the dataset:\n",
    "https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, regularizers\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib.pyplot import specgram\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob \n",
    "import os\n",
    "import pickle\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pathFeature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop(['path', 'labels', 'source'], axis=1), df.labels, test_size = 0.25, shuffle=True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmean = np.mean(X_train, axis=0)\n",
    "Xstd = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - Xmean)/Xstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "\n",
    "# One hot encode the dataset\n",
    "lb = LabelEncoder()\n",
    "Y_train = to_categorical(lb.fit_transform(Y_train))\n",
    "Y_test = to_categorical(lb.fit_transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickel the lb object for future use \n",
    "filename = 'labels.p'\n",
    "outf = open(filename, 'wb')\n",
    "pickle.dump(lb, outf)\n",
    "outf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now because we will use CNN for our baseline model, we need to specify the 3rd dimension, which for us is 1. Its 1 because we're doing a 1D CNN and not a 2D CNN. If we use the MFCC data in its entirity, we could feed that through as the input data, thus making the network a 2D CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv1D(256, 8, padding='same', input_shape=(X_train.shape[1], 1))) #X_train.shape[1] = No. of columns (features)\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 8, padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 8, padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 8, padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 8, padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(14)) #Target Class\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay = 1e-6)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "modelHistory = model.fit(X_train, Y_train, batch_size=16, epochs = 100, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(modelHistory.history['loss'])\n",
    "plt.plot(modelHistory.history['accuracy'])\n",
    "plt.plot(modelHistory.history['val_loss'])\n",
    "plt.plot(modelHistory.history['val_accuracy'])\n",
    "plt.title('Model Loss Graph')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train loss', 'train acc', 'test loss', 'test acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelName = 'Emotion.h5'\n",
    "saveDir = os.path.join(os.getcwd(), 'models')\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.makedirs(saveDir)\n",
    "modelPath = os.path.join(saveDir, modelName)\n",
    "model.save(modelPath)\n",
    "\n",
    "print(f'Saved trained model and weights at {modelPath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelJson = model.to_json()\n",
    "with open('model.json', 'w') as jFile:\n",
    "    jFile.write(modelJson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jFile = open('model.json', 'r')\n",
    "modelJson = jFile.read()\n",
    "jFile.close()\n",
    "\n",
    "loadedModel = model_from_json(modelJson)\n",
    "\n",
    "loadedModel.load_weights('models/Emotion.h5')\n",
    "print('Model Loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Keras Optimizer\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr = 0.00001, decay=1e-6)\n",
    "loadedModel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loadedModel.evaluate(X_test, Y_test, verbose = 0)\n",
    "\n",
    "print(f'{loadedModel.metrics_names[1]}: {score[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = loadedModel.predict(X_test, batch_size = 16, verbose = 1)\n",
    "\n",
    "preds = preds.argmax(axis=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.astype(int).flatten()\n",
    "preds = (lb.inverse_transform((preds)))\n",
    "preds = pd.DataFrame({'predictedvalues': preds})\n",
    "\n",
    "# Actual labels\n",
    "actual=y_test.argmax(axis=1)\n",
    "actual = actual.astype(int).flatten()\n",
    "actual = (lb.inverse_transform((actual)))\n",
    "actual = pd.DataFrame({'actualvalues': actual})\n",
    "\n",
    "# Lets combined both of them into a single dataframe\n",
    "finaldf = actual.join(preds)\n",
    "finaldf[170:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF.to_csv('Predictions.csv', index=True)\n",
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildConfusionMatrix(confusion_matrix, class_names, figsize=(12,12), fontsize=12):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy array\n",
    "        The numpy array object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (12,12).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 12.\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df, annot=True, fmt =\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "\n",
    "    def gender(row):\n",
    "        if row=='female_happy' or 'female_fear' or 'female_surprise' or 'female_disgust' or 'female_sad' or 'female_neutral':\n",
    "            return 'female'\n",
    "        elif row=='male_happy' or 'male_fear' or 'male_surprise' or 'male_disgust' or 'male_sad' or 'male_neutral':\n",
    "            return 'male'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = pd.read_csv('Predictions.csv')\n",
    "classes = finalDF.actualValues.unique()\n",
    "classes.sort()\n",
    "\n",
    "# Confusion Matrix\n",
    "cMatrix = confusion_matrix(finalDF.actualValues, finalDF.predictedValues)\n",
    "\n",
    "print(accuracy_score(finalDF.actualValues, finalDF.predictedValues))\n",
    "\n",
    "buildConfusionMatrix(cMatrix, class_names=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = finaldf.actualvalues.unique()\n",
    "classes.sort()    \n",
    "print(classification_report(finaldf.actualvalues, finaldf.predictedvalues, target_names=classes))"
   ]
  },
  {
   "source": [
    "## My thoughts\n",
    "---\n",
    "\n",
    "The gender seperation turns out to be a curcial implementation in order to accurately classify emotions. Upon closer inspection of the confusion matrix, it seems that female tends to express emotions in a more, obvious manner, for the lack of a better word. Whilst males tend to be very placid or subtle. This is probably why we see the error rate amongst males are really high. For example, male happy and angry gets mixed up quite often."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python37764bittfgpuconda334fc07c846a4864863a233d08755902"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}